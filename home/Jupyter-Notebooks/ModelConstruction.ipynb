{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "5g5gyZZXMHyu",
    "outputId": "2150b58e-6af7-4f4b-da09-6e9c8b65aa2f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: music21 in /usr/local/lib/python3.6/dist-packages (5.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install music21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "eFBpkmmWMHyy",
    "outputId": "d57a59dc-af5e-44e5-b40e-6016f2953f70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow 1.x selected.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from music21 import converter,note,chord,stream,instrument\n",
    "import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading notes files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nG2TX_keMHzj"
   },
   "outputs": [],
   "source": [
    "with open('./drive/My Drive/PreprocessedData/notes','rb') as f:\n",
    "    notes = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "1rCWxRHvelCL",
    "outputId": "5185b4e7-16df-464c-e436-82a5ad7e48e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65730\n",
      "381\n"
     ]
    }
   ],
   "source": [
    "n_vocab = len(set(notes))\n",
    "print(len(notes))\n",
    "print(n_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RMC4DcjDMHzl"
   },
   "source": [
    "## Generating the sequential data for the LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8TwYkmgpMHzl"
   },
   "outputs": [],
   "source": [
    "snotes = sorted(set(notes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vpGmT1PUMHzp"
   },
   "outputs": [],
   "source": [
    "ele_int = dict((ele,idx) for idx,ele in enumerate(snotes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "6XwnRrAGxl2j",
    "outputId": "594994c5-8a2f-49e0-cccd-8078a10f47a6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(868,)"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ele_int[\"F#2\"]\n",
    "n = np.array(notes)\n",
    "n[n==\"F#4\"].shape\n",
    "#n.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1ZnYe7tAMHzr"
   },
   "outputs": [],
   "source": [
    "sequence_length = 50\n",
    "\n",
    "network_input = []\n",
    "network_output = []\n",
    "\n",
    "for i in range(len(notes) - sequence_length):\n",
    "    seq_in = notes[i:i+sequence_length] # in the string format\n",
    "    seq_out = notes[i+sequence_length]\n",
    "    \n",
    "    network_input.append([ele_int[ch] for ch in seq_in])\n",
    "    network_output.append(ele_int[seq_out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "XpFfqIknMHzu",
    "outputId": "4e102194-cb68-435f-92d6-7fa696b22046"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65680\n",
      "[333, 352, 330, 333, 352, 330, 378, 378, 333, 333, 340, 66, 308, 340, 66, 308, 366, 366, 311, 311, 367, 275, 363, 367, 275, 363, 304, 275, 363, 304, 275, 363, 379, 83, 375, 379, 83, 375, 353, 333, 330, 353, 333, 330, 330, 330, 378, 378, 333, 333]\n"
     ]
    }
   ],
   "source": [
    "print(len(network_input))\n",
    "n_patterns = len(network_input)\n",
    "print(network_input[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "N5oKhEhwMHzx",
    "outputId": "a9cf2517-bbdd-438f-d2c5-5ce0e8051926"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65680\n"
     ]
    }
   ],
   "source": [
    "print(len(network_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "8ibYT4VGMHz3",
    "outputId": "f6e65b7e-17bd-49eb-af71-104dce783da0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(65680, 50, 1)\n"
     ]
    }
   ],
   "source": [
    "network_input = np.reshape(network_input,(n_patterns,sequence_length,1))\n",
    "print(network_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v-zWS0WvMHz7"
   },
   "outputs": [],
   "source": [
    "# Normalize our data [0,1]\n",
    "normalized_network_input = network_input/float(n_vocab)\n",
    "#print(normalized_network_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "DY6us-o6MHz-",
    "outputId": "283dad80-9568-480f-e972-0f29e7cf0caf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(65680, 381)\n"
     ]
    }
   ],
   "source": [
    "# Converting the y values into one hot vectors\n",
    "network_output = np_utils.to_categorical(network_output)\n",
    "print(network_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "n_9wCA3MMH0A",
    "outputId": "5fff952e-feb9-4fe2-d7bf-94ca1f0c6f40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(65680, 50, 1)\n",
      "(65680, 381)\n"
     ]
    }
   ],
   "source": [
    "print(normalized_network_input.shape)\n",
    "print(network_output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3PCPI2EEMH0E"
   },
   "source": [
    "## Creating the LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AF170dgeMH0F"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import *\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NDQL0NcI3ASD"
   },
   "outputs": [],
   "source": [
    "adam = Adam(lr = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 432
    },
    "colab_type": "code",
    "id": "tCyfExROMH0I",
    "outputId": "c5719afa-1d86-46df-a9a0-4b5b9c7b6820"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_7 (LSTM)                (None, 50, 512)           1052672   \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 50, 512)           0         \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 50, 512)           2099200   \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 50, 512)           0         \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 512)               2099200   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 381)               195453    \n",
      "=================================================================\n",
      "Total params: 5,709,181\n",
      "Trainable params: 5,709,181\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(512,input_shape = (normalized_network_input.shape[1],normalized_network_input.shape[2]),return_sequences=True))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(LSTM(512, return_sequences=True))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(LSTM(512))\n",
    "model.add(Dense(512,activation = 'relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(n_vocab,activation = 'softmax'))\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy',optimizer = adam)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "YmFVKD1oMH0K",
    "outputId": "077ec555-5047-4853-913a-a208e9fca97a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "65680/65680 [==============================] - 57s 866us/step - loss: 4.8638\n",
      "Epoch 2/100\n",
      "65680/65680 [==============================] - 56s 850us/step - loss: 4.7411\n",
      "Epoch 3/100\n",
      "65680/65680 [==============================] - 56s 853us/step - loss: 4.7314\n",
      "Epoch 4/100\n",
      "65680/65680 [==============================] - 56s 853us/step - loss: 4.7259\n",
      "Epoch 5/100\n",
      "65680/65680 [==============================] - 56s 855us/step - loss: 4.7220\n",
      "Epoch 6/100\n",
      "65680/65680 [==============================] - 56s 853us/step - loss: 4.7201\n",
      "Epoch 7/100\n",
      "65680/65680 [==============================] - 56s 854us/step - loss: 4.6885\n",
      "Epoch 8/100\n",
      "65680/65680 [==============================] - 56s 852us/step - loss: 4.5849\n",
      "Epoch 9/100\n",
      "65680/65680 [==============================] - 56s 853us/step - loss: 4.5441\n",
      "Epoch 10/100\n",
      "65680/65680 [==============================] - 56s 854us/step - loss: 4.5266\n",
      "Epoch 11/100\n",
      "65680/65680 [==============================] - 56s 853us/step - loss: 4.5081\n",
      "Epoch 12/100\n",
      "65680/65680 [==============================] - 56s 854us/step - loss: 4.4893\n",
      "Epoch 13/100\n",
      "65680/65680 [==============================] - 56s 855us/step - loss: 4.4820\n",
      "Epoch 14/100\n",
      "65680/65680 [==============================] - 56s 853us/step - loss: 4.4556\n",
      "Epoch 15/100\n",
      "65680/65680 [==============================] - 56s 853us/step - loss: 4.4301\n",
      "Epoch 16/100\n",
      "65680/65680 [==============================] - 56s 854us/step - loss: 4.3927\n",
      "Epoch 17/100\n",
      "65680/65680 [==============================] - 56s 855us/step - loss: 4.3523\n",
      "Epoch 18/100\n",
      "65680/65680 [==============================] - 56s 856us/step - loss: 4.2986\n",
      "Epoch 19/100\n",
      "65680/65680 [==============================] - 56s 857us/step - loss: 4.2913\n",
      "Epoch 20/100\n",
      "65680/65680 [==============================] - 56s 855us/step - loss: 4.1971\n",
      "Epoch 21/100\n",
      "65680/65680 [==============================] - 56s 854us/step - loss: 4.1484\n",
      "Epoch 22/100\n",
      "65680/65680 [==============================] - 56s 855us/step - loss: 4.0686\n",
      "Epoch 23/100\n",
      "65680/65680 [==============================] - 56s 855us/step - loss: 3.9888\n",
      "Epoch 24/100\n",
      "65680/65680 [==============================] - 56s 856us/step - loss: 3.9196\n",
      "Epoch 25/100\n",
      "65680/65680 [==============================] - 56s 853us/step - loss: 3.8264\n",
      "Epoch 26/100\n",
      "65680/65680 [==============================] - 56s 854us/step - loss: 3.7179\n",
      "Epoch 27/100\n",
      "65680/65680 [==============================] - 56s 855us/step - loss: 3.6199\n",
      "Epoch 28/100\n",
      "65680/65680 [==============================] - 56s 855us/step - loss: 3.4839\n",
      "Epoch 29/100\n",
      "65680/65680 [==============================] - 56s 854us/step - loss: 3.3773\n",
      "Epoch 30/100\n",
      "65680/65680 [==============================] - 56s 854us/step - loss: 3.2563\n",
      "Epoch 31/100\n",
      "65680/65680 [==============================] - 56s 854us/step - loss: 3.1349\n",
      "Epoch 32/100\n",
      "65680/65680 [==============================] - 56s 855us/step - loss: 3.0263\n",
      "Epoch 33/100\n",
      "65680/65680 [==============================] - 56s 856us/step - loss: 2.9073\n",
      "Epoch 34/100\n",
      "65680/65680 [==============================] - 56s 855us/step - loss: 2.8104\n",
      "Epoch 35/100\n",
      "65680/65680 [==============================] - 56s 855us/step - loss: 2.6630\n",
      "Epoch 36/100\n",
      "65680/65680 [==============================] - 56s 854us/step - loss: 2.5603\n",
      "Epoch 37/100\n",
      "65680/65680 [==============================] - 56s 854us/step - loss: 2.4518\n",
      "Epoch 38/100\n",
      "65680/65680 [==============================] - 56s 854us/step - loss: 2.3820\n",
      "Epoch 39/100\n",
      "65680/65680 [==============================] - 56s 853us/step - loss: 2.2476\n",
      "Epoch 40/100\n",
      "65680/65680 [==============================] - 56s 854us/step - loss: 2.1564\n",
      "Epoch 41/100\n",
      "65680/65680 [==============================] - 56s 854us/step - loss: 2.0711\n",
      "Epoch 42/100\n",
      "65680/65680 [==============================] - 56s 856us/step - loss: 1.9710\n",
      "Epoch 43/100\n",
      "65680/65680 [==============================] - 56s 855us/step - loss: 1.8842\n",
      "Epoch 44/100\n",
      "65680/65680 [==============================] - 56s 854us/step - loss: 1.8212\n",
      "Epoch 45/100\n",
      "65680/65680 [==============================] - 56s 855us/step - loss: 1.7221\n",
      "Epoch 46/100\n",
      "65680/65680 [==============================] - 56s 855us/step - loss: 1.6601\n",
      "Epoch 47/100\n",
      "65680/65680 [==============================] - 56s 855us/step - loss: 1.6436\n",
      "Epoch 48/100\n",
      "65680/65680 [==============================] - 56s 854us/step - loss: 1.5100\n",
      "Epoch 49/100\n",
      "65680/65680 [==============================] - 56s 855us/step - loss: 1.4447\n",
      "Epoch 50/100\n",
      "65680/65680 [==============================] - 56s 855us/step - loss: 1.4039\n",
      "Epoch 51/100\n",
      "65680/65680 [==============================] - 56s 856us/step - loss: 1.3266\n",
      "Epoch 52/100\n",
      "65680/65680 [==============================] - 56s 853us/step - loss: 1.2740\n",
      "Epoch 53/100\n",
      "65680/65680 [==============================] - 56s 854us/step - loss: 1.2409\n",
      "Epoch 54/100\n",
      "65680/65680 [==============================] - 56s 855us/step - loss: 1.1871\n",
      "Epoch 55/100\n",
      "65680/65680 [==============================] - 56s 855us/step - loss: 1.1026\n",
      "Epoch 56/100\n",
      "65680/65680 [==============================] - 56s 856us/step - loss: 1.0696\n",
      "Epoch 57/100\n",
      "65680/65680 [==============================] - 56s 855us/step - loss: 1.0068\n",
      "Epoch 58/100\n",
      "65680/65680 [==============================] - 56s 857us/step - loss: 1.0125\n",
      "Epoch 59/100\n",
      "65680/65680 [==============================] - 56s 854us/step - loss: 0.9359\n",
      "Epoch 60/100\n",
      "65680/65680 [==============================] - 56s 854us/step - loss: 0.8917\n",
      "Epoch 61/100\n",
      "65680/65680 [==============================] - 56s 855us/step - loss: 0.8590\n",
      "Epoch 62/100\n",
      "65680/65680 [==============================] - 56s 857us/step - loss: 0.8390\n",
      "Epoch 63/100\n",
      "65680/65680 [==============================] - 56s 855us/step - loss: 0.8030\n",
      "Epoch 64/100\n",
      "65680/65680 [==============================] - 56s 857us/step - loss: 0.7731\n",
      "Epoch 65/100\n",
      "65680/65680 [==============================] - 56s 854us/step - loss: 0.7207\n",
      "Epoch 66/100\n",
      "65680/65680 [==============================] - 56s 856us/step - loss: 0.6994\n",
      "Epoch 67/100\n",
      "65680/65680 [==============================] - 56s 855us/step - loss: 0.6646\n",
      "Epoch 68/100\n",
      "65680/65680 [==============================] - 56s 856us/step - loss: 0.6433\n",
      "Epoch 69/100\n",
      "65680/65680 [==============================] - 56s 857us/step - loss: 0.6274\n",
      "Epoch 70/100\n",
      "65680/65680 [==============================] - 56s 857us/step - loss: 0.6110\n",
      "Epoch 71/100\n",
      "65680/65680 [==============================] - 56s 857us/step - loss: 0.5797\n",
      "Epoch 72/100\n",
      "65680/65680 [==============================] - 56s 857us/step - loss: 0.5584\n",
      "Epoch 73/100\n",
      "65680/65680 [==============================] - 56s 859us/step - loss: 0.5590\n",
      "Epoch 74/100\n",
      "65680/65680 [==============================] - 56s 855us/step - loss: 0.5401\n",
      "Epoch 75/100\n",
      "65680/65680 [==============================] - 56s 856us/step - loss: 0.4975\n",
      "Epoch 76/100\n",
      "65680/65680 [==============================] - 56s 855us/step - loss: 0.4752\n",
      "Epoch 77/100\n",
      "65680/65680 [==============================] - 56s 855us/step - loss: 0.4515\n",
      "Epoch 78/100\n",
      "65680/65680 [==============================] - 56s 854us/step - loss: 0.4359\n",
      "Epoch 79/100\n",
      "65680/65680 [==============================] - 56s 856us/step - loss: 0.4412\n",
      "Epoch 80/100\n",
      "65680/65680 [==============================] - 56s 853us/step - loss: 0.4260\n",
      "Epoch 81/100\n",
      "65680/65680 [==============================] - 56s 855us/step - loss: 0.4023\n",
      "Epoch 82/100\n",
      "65680/65680 [==============================] - 56s 855us/step - loss: 0.3992\n",
      "Epoch 83/100\n",
      "65680/65680 [==============================] - 56s 855us/step - loss: 0.3786\n",
      "Epoch 84/100\n",
      "65680/65680 [==============================] - 56s 858us/step - loss: 0.3652\n",
      "Epoch 85/100\n",
      "65680/65680 [==============================] - 56s 857us/step - loss: 0.3555\n",
      "Epoch 86/100\n",
      "65680/65680 [==============================] - 56s 855us/step - loss: 0.3781\n",
      "Epoch 87/100\n",
      "65680/65680 [==============================] - 56s 855us/step - loss: 0.3534\n",
      "Epoch 88/100\n",
      "65680/65680 [==============================] - 56s 854us/step - loss: 0.3356\n",
      "Epoch 89/100\n",
      "65680/65680 [==============================] - 56s 855us/step - loss: 0.3158\n",
      "Epoch 90/100\n",
      "65680/65680 [==============================] - 56s 855us/step - loss: 0.3333\n",
      "Epoch 91/100\n",
      "65680/65680 [==============================] - 56s 855us/step - loss: 0.3039\n",
      "Epoch 92/100\n",
      "65680/65680 [==============================] - 56s 856us/step - loss: 0.2923\n",
      "Epoch 93/100\n",
      "65680/65680 [==============================] - 56s 853us/step - loss: 0.2885\n",
      "Epoch 94/100\n",
      "65680/65680 [==============================] - 56s 853us/step - loss: 0.2836\n",
      "Epoch 95/100\n",
      "65680/65680 [==============================] - 56s 855us/step - loss: 0.2626\n",
      "Epoch 96/100\n",
      "65680/65680 [==============================] - 56s 855us/step - loss: 0.8092\n",
      "Epoch 97/100\n",
      "65680/65680 [==============================] - 56s 854us/step - loss: 0.3137\n",
      "Epoch 98/100\n",
      "65680/65680 [==============================] - 56s 854us/step - loss: 0.2535\n",
      "Epoch 99/100\n",
      "65680/65680 [==============================] - 56s 855us/step - loss: 0.2402\n",
      "Epoch 100/100\n",
      "65680/65680 [==============================] - 56s 854us/step - loss: 0.2288\n"
     ]
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint(\"model.hdf5\",monitor='loss',verbose=0,save_best_only=True,mode = 'min')\n",
    "\n",
    "hist = model.fit(normalized_network_input,network_output,epochs = 100,batch_size = 1024,callbacks = [checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j7tERquHMH0M"
   },
   "outputs": [],
   "source": [
    "## model.save(\"model.hdf5\")\n",
    "## model = load_model(\"model.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v_5jdWLifltY"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "MusicGeneration.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
